{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cb8e631",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import urllib.error # Для обработки ошибок HTTP и URL\n",
    "import zipfile\n",
    "import os\n",
    "import shutil # Для удаления директории, если нужно\n",
    "import sys # Для sys.stdout.flush()\n",
    "import time # Для задержки между попытками\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d14f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 1. Конфигурация и пути к данным ---\n",
    "# Вам нужно будет изменить эти пути в соответствии с вашей локальной структурой файлов.\n",
    "DATA_DIR = 'C:\\\\Users\\\\Sirius\\\\Desktop\\\\neuronetwork\\\\GOTOVO' # Например: 'C:/Users/User/Desktop/my_dataset'\n",
    "IMAGE_SUBDIR = 'processed_oil_spill_images' # Поддиректория, где хранятся TIF изображения\n",
    "MASK_SUBDIR = 'processed_mask_oil_spill_images'   # Поддиректория, где хранятся пиксельные маски\n",
    "\n",
    "IMAGE_HEIGHT = 256 # Укажите желаемую высоту изображений после изменения размера\n",
    "IMAGE_WIDTH = 256  # Укажите желаемую ширину изображений после изменения размера\n",
    "NUM_CHANNELS = 2   # Теперь у нас обычные TIF изображения.\n",
    "                   # Если они черно-белые (градации серого), оставьте 1.\n",
    "                   # Если они цветные (RGB), измените на 3.\n",
    "NUM_CLASSES = 1    # Для бинарной маски (например, объект/фон) - 1 класс.\n",
    "                   # Если маска имеет несколько классов (например, разные типы объектов),\n",
    "                   # измените на количество классов и используйте 'categorical_crossentropy'\n",
    "                   # в качестве функции потерь.\n",
    "\n",
    "# --- 2. Загрузка и предварительная обработка данных ---\n",
    "\n",
    "def load_image_and_mask(image_path, mask_path, target_size=(IMAGE_HEIGHT, IMAGE_WIDTH)):\n",
    "    \"\"\"\n",
    "    Загружает TIF изображение и соответствующую пиксельную маску.\n",
    "    Эта функция адаптирована для обычных TIF изображений.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Загрузка изображения. Используем IMREAD_UNCHANGED для сохранения всех каналов,\n",
    "        # затем преобразуем в нужное количество каналов.\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "        # Проверка и преобразование количества каналов\n",
    "        if image.ndim == 2: # Если изображение одноканальное (градации серого)\n",
    "            if NUM_CHANNELS == 1:\n",
    "                image = np.expand_dims(image, axis=-1) # Добавляем измерение для канала\n",
    "            \n",
    "            elif NUM_CHANNELS == 3:\n",
    "                # Если ожидается 3 канала, но загружено 1, можно продублировать канал (для RGB)\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "            else:\n",
    "                raise ValueError(f\"Несоответствие каналов: Загружено 1, ожидается {NUM_CHANNELS}\")\n",
    "        elif image.ndim == 3: # Если изображение многоканальное (например, RGB)\n",
    "        \n",
    "            if NUM_CHANNELS == 3:\n",
    "                # Если ожидается 3 канала, и загружено 3, все хорошо\n",
    "                pass\n",
    "                \n",
    "            elif NUM_CHANNELS == 1:\n",
    "                # Если ожидается 1 канал, но загружено 3, преобразуем в градации серого\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                image = np.expand_dims(image, axis=-1) # Добавляем измерение для канала\n",
    "            \n",
    "            else:\n",
    "                raise ValueError(f\"Несоответствие каналов: Загружено {image.shape[-1]}, ожидается {NUM_CHANNELS}\")\n",
    "        else:\n",
    "            raise ValueError(f\"Неподдерживаемая размерность изображения: {image.ndim}\")\n",
    "        \n",
    "        # Загрузка маски (обычно одноканальное изображение)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Изменение размера\n",
    "        image = cv2.resize(image, target_size)\n",
    "        mask = cv2.resize(mask, target_size, interpolation=cv2.INTER_NEAREST) # Для масок используем INTER_NEAREST, чтобы сохранить дискретные значения\n",
    "\n",
    "        # Нормализация изображений (0-1)\n",
    "        image = image.astype(np.float32) / 255.0\n",
    "        # Нормализация маски (0 или 1 для бинарной маски)\n",
    "        # Убедитесь, что маска содержит только значения 0 и 1 (или 0 и 255, которые затем делятся на 255)\n",
    "        mask = mask.astype(np.float32) / 255.0\n",
    "        mask = np.expand_dims(mask, axis=-1) # Добавляем измерение для канала маски\n",
    "\n",
    "        return image, mask\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при загрузке или обработке {image_path} или {mask_path}: {e}\")\n",
    "        return None, None\n",
    "def load_dataset(data_dir, image_subdir, mask_subdir):\n",
    "    \"\"\"\n",
    "    Собирает пути ко всем изображениям и маскам в датасете.\n",
    "    \"\"\"\n",
    "    image_paths = sorted([os.path.join(data_dir, image_subdir, f) for f in os.listdir(os.path.join(data_dir, image_subdir)) if f.lower().endswith(('.png', '.tif', '.tiff', '.jpg', '.jpeg'))])\n",
    "    mask_paths = sorted([os.path.join(data_dir, mask_subdir, f) for f in os.listdir(os.path.join(data_dir, mask_subdir)) if f.lower().endswith(('.png', '.tif', '.tiff', '.jpg', '.jpeg'))])\n",
    "\n",
    "    # Убедитесь, что количество изображений и масок совпадает\n",
    "    if len(image_paths) != len(mask_paths):\n",
    "        raise ValueError(\"Количество изображений и масок не совпадает!\")\n",
    "\n",
    "    # Простая проверка соответствия имен файлов (если они соответствуют)\n",
    "    # Если имена файлов не соответствуют напрямую, вам потребуется более сложная логика сопоставления\n",
    "    # Например, если image_001.tif соответствует mask_001.png\n",
    "    # for img_p, msk_p in zip(image_paths, mask_paths):\n",
    "    #     if os.path.basename(img_p).split('.')[0] != os.path.basename(msk_p).split('.')[0]:\n",
    "    #         print(f\"Предупреждение: Имена файлов не совпадают: {os.path.basename(img_p)} и {os.path.basename(msk_p)}\")\n",
    "\n",
    "    images = []\n",
    "    masks = []\n",
    "    for i in range(len(image_paths)):\n",
    "        img, msk = load_image_and_mask(image_paths[i], mask_paths[i])\n",
    "        if img is not None and msk is not None:\n",
    "            images.append(img)\n",
    "            masks.append(msk)\n",
    "\n",
    "    return np.array(images), np.array(masks)\n",
    "\n",
    "print(\"Загрузка данных...\")\n",
    "try:\n",
    "    X, y = load_dataset(DATA_DIR, IMAGE_SUBDIR, MASK_SUBDIR)\n",
    "    print(f\"Загружено {len(X)} изображений и масок.\")\n",
    "    print(f\"Форма изображений: {X.shape}\") # Ожидается (количество_образцов, высота, ширина, количество_каналов)\n",
    "    print(f\"Форма масок: {y.shape}\")     # Ожидается (количество_образцов, высота, ширина, 1)\n",
    "\n",
    "    # Разделение данных на обучающую и валидационную выборки\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    print(f\"Обучающая выборка: {X_train.shape}, {y_train.shape}\")\n",
    "    print(f\"Валидационная выборка: {X_val.shape}, {y_val.shape}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Произошла ошибка при загрузке или разделении данных: {e}\")\n",
    "    print(\"Пожалуйста, проверьте пути к файлам и формат ваших данных.\")\n",
    "    # Выход из программы или использование заглушечных данных для демонстрации модели\n",
    "    X_train = np.random.rand(10, IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS)\n",
    "    y_train = np.random.randint(0, 2, size=(10, IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CLASSES))\n",
    "    X_val = np.random.rand(2, IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS)\n",
    "    y_val = np.random.randint(0, 2, size=(2, IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CLASSES))\n",
    "    print(\"Используются заглушечные данные для продолжения демонстрации модели.\")\n",
    "\n",
    "\n",
    "# --- 3. Определение архитектуры сверточной нейросети (U-Net-подобная) ---\n",
    "\n",
    "def unet_model(input_size=(IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS), num_classes=NUM_CLASSES):\n",
    "    inputs = keras.Input(input_size)\n",
    "\n",
    "    # Encoder (Путь сжатия)\n",
    "    conv1 = layers.Conv2D(32, 3, activation='relu', padding='same')(inputs) #1\n",
    "    conv1 = layers.Conv2D(32, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = layers.Conv2D(64, 3, activation='relu', padding='same')(pool1) #2\n",
    "    conv2 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = layers.Conv2D(128, 3, activation='relu', padding='same')(pool2) #3\n",
    "    conv3 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv3)\n",
    "    pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = layers.Conv2D(256, 3, activation='relu', padding='same')(pool3) #4\n",
    "    conv4 = layers.Conv2D(256, 3, activation='relu', padding='same')(conv4)\n",
    "    pool4 = layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    # Bottleneck (Дно)\n",
    "    conv5 = layers.Conv2D(512, 3, activation='relu', padding='same')(pool4) #5\n",
    "    conv5 = layers.Conv2D(512, 3, activation='relu', padding='same')(conv5)\n",
    "\n",
    "# Decoder (Путь расширения)\n",
    "    up6 = layers.UpSampling2D(size=(2, 2))(conv5)\n",
    "    up6 = layers.Conv2D(256, 2, activation='relu', padding='same')(up6)\n",
    "    merge6 = layers.concatenate([conv4, up6], axis=3) # Skip connection\n",
    "    conv6 = layers.Conv2D(256, 3, activation='relu', padding='same')(merge6)\n",
    "    conv6 = layers.Conv2D(256, 3, activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = layers.UpSampling2D(size=(2, 2))(conv6)\n",
    "    up7 = layers.Conv2D(128, 2, activation='relu', padding='same')(up7)\n",
    "    merge7 = layers.concatenate([conv3, up7], axis=3) # Skip connection\n",
    "    conv7 = layers.Conv2D(128, 3, activation='relu', padding='same')(merge7)\n",
    "    conv7 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = layers.UpSampling2D(size=(2, 2))(conv7)\n",
    "    up8 = layers.Conv2D(64, 2, activation='relu', padding='same')(up8)\n",
    "    merge8 = layers.concatenate([conv2, up8], axis=3) # Skip connection\n",
    "    conv8 = layers.Conv2D(64, 3, activation='relu', padding='same')(merge8)\n",
    "    conv8 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = layers.UpSampling2D(size=(2, 2))(conv8)\n",
    "    up9 = layers.Conv2D(32, 2, activation='relu', padding='same')(up9)\n",
    "    merge9 = layers.concatenate([conv1, up9], axis=3) # Skip connection\n",
    "    conv9 = layers.Conv2D(32, 3, activation='relu', padding='same')(merge9)\n",
    "    conv9 = layers.Conv2D(32, 3, activation='relu', padding='same')(conv9)\n",
    "\n",
    "    # Выходной слой\n",
    "    # Для бинарной сегментации (один класс маски):\n",
    "    if num_classes == 1:\n",
    "        outputs = layers.Conv2D(num_classes, 1, activation='sigmoid')(conv9)\n",
    "        loss_function = 'binary_crossentropy'\n",
    "    # Для многоклассовой сегментации:\n",
    "    else:\n",
    "        outputs = layers.Conv2D(num_classes, 1, activation='softmax')(conv9)\n",
    "        loss_function = 'categorical_crossentropy'\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model, loss_function\n",
    "\n",
    "print(\"Создание модели нейросети...\")\n",
    "model, loss_func = unet_model()\n",
    "model.summary()\n",
    "\n",
    "# --- 4. Компиляция модели ---\n",
    "print(\"Компиляция модели...\")\n",
    "model.compile(optimizer='adam', loss=loss_func, metrics=['accuracy'])\n",
    "\n",
    "# --- 5. Обучение модели ---\n",
    "print(\"Обучение модели...\")\n",
    "# Вы можете настроить количество эпох и размер батча\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# --- 6. Оценка модели (опционально) ---\n",
    "print(\"\\nОценка модели на валидационных данных:\")\n",
    "loss, accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "print(f\"Потери на валидационной выборке: {loss:.4f}\")\n",
    "print(f\"Точность на валидационной выборке: {accuracy:.4f}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
